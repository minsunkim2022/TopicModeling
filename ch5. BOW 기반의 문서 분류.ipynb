{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8247bd8b",
   "metadata": {},
   "source": [
    "# 20 뉴스그룹 데이터 준비 및 특성 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282c828",
   "metadata": {},
   "source": [
    "### 데이터셋 확인 및 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22a509bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 2034\n",
      "#Test set size: 1353\n",
      "#Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "#Train labels: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 20개의 토픽 중 선택하고자 하는 토픽을 리스트로 생성\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# 학습 데이터셋 가져오기\n",
    "newsgroups_train = fetch_20newsgroups(subset = 'train',\n",
    "# 메일 내용에서 hint가 되는 부분 삭제 - 순수하게 내용만으로 분류하기 위해                                     \n",
    "                                     remove = ('headers', 'footers', 'quotes'),\n",
    "                                     categories = categories)\n",
    "# 평가 데이터셋 가져오기\n",
    "newsgroups_test = fetch_20newsgroups(subset = 'test',\n",
    "                                    remove = ('headers', 'footers', 'quotes'),\n",
    "                                    categories = categories)\n",
    "\n",
    "print(\"#Train set size:\", len(newsgroups_train.data))\n",
    "print(\"#Test set size:\", len(newsgroups_test.data))\n",
    "print(\"#Selected categories:\", newsgroups_train.target_names)\n",
    "print(\"#Train labels:\", set(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b580cd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set text samples: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "#Train set label samples: 1\n",
      "#Test set text samples: TRry the SKywatch project in  Arizona.\n",
      "#Test set label samples: 2\n"
     ]
    }
   ],
   "source": [
    "# 데이터의 첫째 값 출력해보기\n",
    "print(\"#Train set text samples:\", newsgroups_train.data[0])\n",
    "print(\"#Train set label samples:\", newsgroups_train.target[0])\n",
    "print(\"#Test set text samples:\", newsgroups_test.data[0])\n",
    "print(\"#Test set label samples:\", newsgroups_test.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45c20b",
   "metadata": {},
   "source": [
    "### 카운트 기반 특성 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "955b85e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (2034, 2000)\n",
      "Test set dimension: (1353, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train.data # 학습 데이터셋 문서\n",
    "y_train = newsgroups_train.target # 학습 데이터셋 라벨\n",
    "\n",
    "X_test = newsgroups_test.data # 평가 데이터셋 문서\n",
    "y_test = newsgroups_test.target # 평가 데이터셋 라벨\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "# 5개 미만의 문서에서 나타나는 단어는 outliers라고 판단해 제외시킴\n",
    "# 문서의 50%를 초과해 나타나는 단어는 지극히 general한 단어라고 판단해 제외시킴\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train) # train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape)\n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c61f060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 : 0,000 : 0,01 : 0,04 : 0,05 : 0,10 : 0,100 : 0,1000 : 0,11 : 0,12 : 0,128 : 0,129 : 0,13 : 0,130 : 0,14 : 0,15 : 0,16 : 0,17 : 0,18 : 0,19 : 0,1987 : 0,1988 : 0,1989 : 0,1990 : 0,1991 : 0,1992 : 0,1993 : 0,20 : 0,200 : 0,202 : 0,21 : 0,22 : 0,23 : 0,24 : 0,25 : 0,256 : 0,26 : 0,27 : 0,28 : 0,2d : 0,30 : 0,300 : 0,31 : 0,32 : 0,33 : 0,34 : 0,35 : 0,39 : 0,3d : 0,40 : 0,400 : 0,42 : 0,45 : 0,50 : 0,500 : 0,60 : 0,600 : 0,65 : 0,70 : 0,75 : 0,80 : 0,800 : 0,90 : 0,900 : 0,91 : 0,92 : 0,93 : 0,95 : 0,_the : 0,ability : 0,able : 1,abortion : 0,about : 1,above : 0,absolute : 0,absolutely : 0,ac : 0,accept : 0,acceptable : 0,accepted : 0,access : 0,according : 0,account : 0,accurate : 0,across : 0,act : 0,action : 0,actions : 0,active : 0,activities : 0,activity : 0,acts : 0,actual : 0,actually : 0,ad : 0,add : 0,added : 0,addition : 0,additional : 0,address : 0,"
     ]
    }
   ],
   "source": [
    "for word, count in zip(\n",
    "cv.get_feature_names_out()[:100], X_train_cv[0].toarray()[0, :100]\n",
    "):\n",
    "    print(word, ':', count, end = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9eb4d",
   "metadata": {},
   "source": [
    "### 머신러닝과 문서 분류 과정에 대한 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb8183",
   "metadata": {},
   "source": [
    "### 나이브 베이즈 분류기(Naive Bayse Classifier)를 이용한 문서 분류\n",
    "\n",
    "1. http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c380dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.824\n",
      "Test set score: 0.732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 분류기 선언\n",
    "NB_clf = MultinomialNB()\n",
    "# train set을 이용해 분류기 학습\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "\n",
    "# train set에 대한 예측 정확도 확인\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "# test set에 대한 예측 정확도 확인\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9334ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#First document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
      "#Second document and label in test data: The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available. 1\n",
      "#Predicted labels: [2 1]\n",
      "#Predicted categories: sci.space comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print('#First document and label in test data:', X_test[0], y_test[0])\n",
    "print('#Second document and label in test data:', X_test[1], y_test[1])\n",
    "\n",
    "pred = NB_clf.predict(X_test_cv[:2])\n",
    "\n",
    "print('#Predicted labels:', pred)\n",
    "print('#Predicted categories:', newsgroups_train.target_names[pred[0]], newsgroups_train.target_names[pred[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9950466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.862\n",
      "Test set score: :0.741\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer 대신 TfidfVectorizer 사용\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CountVectorizer와 동일한 인수를 사용\n",
    "tfidf = TfidfVectorizer(max_features = 2000, min_df = 5, max_df=  0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "\n",
    "# tfidf train set을 이용해 분류기를 새로 학습\n",
    "NB_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# train set에 대한 예측 정확도 확인\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
    "# test set에 대한 예측 정확도 확인\n",
    "print('Test set score: :{:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384724d",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀분석을 이용한 문서 분류\n",
    "\n",
    "1: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe0e11f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.930\n",
      "Test set score: 0.734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Count vector에 대해 regression을 해서 NB와 비교\n",
    "LR_clf = LogisticRegression()\n",
    "LR_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7723a",
   "metadata": {},
   "source": [
    "### 릿지 회귀(ridge regression)을 이용한 과적합 방지\n",
    "\n",
    "* L2 정규화 사용\n",
    "* 특성에 대한 계수가 지나치게 커지는 것을 억제한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac778cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.960\n",
      "Test set score: 0.735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9117bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max alpha 1.600 at max validation score 0.826\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
    "X_train_tfidf, y_train, test_size = 0.2, random_state = 42)\n",
    "\n",
    "max_score = 0\n",
    "max_alpha = 0\n",
    "for alpha in np.arange(0.1, 10, 0.1): # alpha를 0.1부터 10까지 0.1씩 증가\n",
    "    ridge_clf = RidgeClassifier(alpha = alpha)\n",
    "    ridge_clf.fit(X_train_ridge, y_train_ridge)\n",
    "    # 검정 데이터셋에 대해 정확도를 측정\n",
    "    score = ridge_clf.score(X_val_ridge, y_val_ridge)\n",
    "    if score > max_score: # 정확도가 이전의 정확도 최댓값보다 크면 최댓값을 변경한다.\n",
    "        max_score = score\n",
    "        max_alpha = alpha\n",
    "print('Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92a411c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.947\n",
      "Test set score: 0.739\n"
     ]
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifier(alpha = 1.6)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccf241",
   "metadata": {},
   "source": [
    "### 라쏘 회귀분석(lasso regression)을 이용한 특성 선택\n",
    "\n",
    "* L1 정규화 사용\n",
    "* 특성의 계수가 0에 가까워지면 이를 0으로 바꿔, 특성값을 아예 사용하지 않게 만듦(특성의 수를 줄임)\n",
    "* parameter C는 alpha의 역수로, C 값이 커질수록 정규화가 약해진다.\n",
    "\n",
    "1. http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9021127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.819\n",
      "#Test set score: 0.724\n",
      "#Used features count: 437 out of 2000\n"
     ]
    }
   ],
   "source": [
    "# Lasso는 동일한 LogisticRegression을 사용하면서 매개변수를 지정\n",
    "lasso_clf = LogisticRegression(penalty = 'l1', solver = 'liblinear', C=1)\n",
    "\n",
    "lasso_clf .fit(X_train_tfidf, y_train) # train data로 학습\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# 계수(coefficient) 중에서 0이 아닌 것들의 개수를 출력\n",
    "print(\n",
    "    '#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)),\n",
    "    'out of',\n",
    "    X_train_tfidf.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b4e71",
   "metadata": {},
   "source": [
    "### 결정트리 등을 이용한 기타 문서 분류 방법\n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "3. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcd50f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Decision Tree train set score: 0.977\n",
      "#Decision Tree test set score: 0.536\n",
      "#Random Forest train set score: 0.977\n",
      "#Random Forest test set score: 0.685\n",
      "#Gradient Boosting train set score: 0.933\n",
      "#Gradient Boosting test set score: 0.696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=7)\n",
    "tree.fit(X_train_tfidf, y_train)\n",
    "print('#Decision Tree train set score: {:.3f}'.format(tree.score(X_train_tfidf, y_train)))\n",
    "print('#Decision Tree test set score: {:.3f}'.format(tree.score(X_test_tfidf, y_test)))\n",
    "\n",
    "forest = RandomForestClassifier(random_state=7)\n",
    "forest.fit(X_train_tfidf, y_train)\n",
    "print('#Random Forest train set score: {:.3f}'.format(forest.score(X_train_tfidf, y_train)))\n",
    "print('#Random Forest test set score: {:.3f}'.format(forest.score(X_test_tfidf, y_test)))\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=7)\n",
    "gb.fit(X_train_tfidf, y_train)\n",
    "print('#Gradient Boosting train set score: {:.3f}'.format(gb.score(X_train_tfidf, y_train)))\n",
    "print('#Gradient Boosting test set score: {:.3f}'.format(gb.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10eb77cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space: 0.126, graphics: 0.080, atheism: 0.024, thanks: 0.023, file: 0.021, orbit: 0.020, jesus: 0.018, god: 0.018, hi: 0.017, nasa: 0.015, image: 0.015, files: 0.014, christ: 0.010, moon: 0.010, bobby: 0.010, launch: 0.010, looking: 0.010, christian: 0.010, atheists: 0.009, christians: 0.009, fbi: 0.009, 3d: 0.008, you: 0.008, not: 0.008, islamic: 0.007, religion: 0.007, spacecraft: 0.007, flight: 0.007, computer: 0.007, islam: 0.007, ftp: 0.006, color: 0.006, software: 0.005, atheist: 0.005, card: 0.005, people: 0.005, koresh: 0.005, his: 0.005, kent: 0.004, sphere: 0.004, "
     ]
    }
   ],
   "source": [
    "sorted_feature_importances = sorted(zip(tfidf.get_feature_names_out(), gb.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "for feature, value in sorted_feature_importances[:40]:\n",
    "    print('%s: %.3f' % (feature, value), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201a3d4f",
   "metadata": {},
   "source": [
    "### 성능을 높이기 위한 방법들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df181d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.930\n",
      "#Test set score: 0.751\n"
     ]
    }
   ],
   "source": [
    "# 필요한 library들을 import\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규포현식으로 토크나이저를 정의\n",
    "english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text.lower()) #이렇게 해도 되는지 확인\n",
    "    # stopwords 제외\n",
    "    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
    "    # portr stemmer 적용\n",
    "    features = (list(map(lambda token: PorterStemmer().stem(token),words)))\n",
    "    return features\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=0.5) # 새로 정의한 토크나이저 사용\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "\n",
    "#tfidf vector를 이용해서 분류기 학습\n",
    "LR_clf = LogisticRegression() #분류기 선언\n",
    "LR_clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 \n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90f3ca82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LR_clf.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cf93947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set dimension: (2034, 20085)\n",
      "#Test set dimension: (1353, 20085)\n",
      "#Train set score: 0.969\n",
      "#Test set score: 0.768\n",
      "#Train set score: 0.971\n",
      "#Test set score: 0.793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "print('#Train set dimension:', X_train_tfidf.shape) # 실제로 몇개의 특성이 사용되었는지 확인\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환\n",
    "print('#Test set dimension:', X_test_tfidf.shape)\n",
    "\n",
    "ridge_clf = RidgeClassifier(alpha=2.4)\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('#Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "NB_clf = MultinomialNB(alpha=0.01) # 분류기 선언\n",
    "NB_clf.fit(X_train_tfidf, y_train) #train set을 이용하여 분류기(classifier)를 학습\n",
    "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인\n",
    "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4d123",
   "metadata": {},
   "source": [
    "### 카운트 기반의 문제점과 N-gram\n",
    "\n",
    "* BOW 기반의 분류 기법은 단어들의 순서를 고려하지 않는다는 문제가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd5e22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 11483)\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cachedStopWords = stopwords.words('english')\n",
    "tfidf = TfidfVectorizer(token_pattern = \"[a-zA-Z']{3,}\", # 토큰화를 위한 정규식\n",
    "                       decode_error = 'ignore',\n",
    "                       lowercase = True,\n",
    "                       stop_words = stopwords.words('english'),\n",
    "                       max_df = 0.5,\n",
    "                       min_df = 2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71525510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.976\n",
      "Test set score: 0.765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier()\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb16aeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 26541)\n"
     ]
    }
   ],
   "source": [
    "# bi-gram 적용\n",
    "tfidf = TfidfVectorizer(token_pattern = \"[a-zA-z']{3,}\",\n",
    "                       decode_error = 'ignore',\n",
    "                       lowercase = True,\n",
    "                       stop_words = stopwords.words('english'),\n",
    "                       ngram_range = (1,2), # 바이그램 설정\n",
    "                        max_df = 0.5,\n",
    "                       min_df = 2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.fit(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c63ffd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi-gram samples: [\"'cause can't\", \"'em better\", \"'em better shots\", \"'expected errors'\", \"'expected errors' basically\", \"'karla' next\", \"'karla' next one\", \"'nodis' password\", \"'nodis' password also\", \"'official doctrine\"]\n",
      "Train set score: 0.976\n",
      "Test set score: 0.775\n"
     ]
    }
   ],
   "source": [
    "bigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 1]\n",
    "print('bi-gram samples:', bigram_features[:10])\n",
    "\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "53e1e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 32943)\n",
      "tri-gram samples: [\"'em better shots\", \"'expected errors' basically\", \"'karla' next one\", \"'nodis' password also\", \"'official doctrine think\", \"'ok see warning\", \"'what's moonbase good\", 'aas american astronautical', 'ability means infallible', 'able accept donations']\n",
      "Train set score: 0.976\n",
      "Test set score: 0.775\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\", \n",
    "                        decode_error ='ignore', \n",
    "                        lowercase=True, \n",
    "                        stop_words = stopwords.words('english'),\n",
    "                        ngram_range=(1, 3),\n",
    "                        max_df=0.5,\n",
    "                        min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "trigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 2]\n",
    "print('tri-gram samples:', trigram_features[:10])\n",
    "\n",
    "ridge_clf.fit(X_train_tfidf, y_train) #학습\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730c2b7",
   "metadata": {},
   "source": [
    "### 한글 문서의 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a7085f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/daum_movie_reviews.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ead30de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "신과함께      4947\n",
       "택시운전사     2322\n",
       "인피니티 워    2042\n",
       "범죄도시      1939\n",
       "곤지암       1547\n",
       "라라랜드      1150\n",
       "코코         778\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d1905f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 11043\n",
      "#Test set size: 3682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.title, random_state = 0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨\n",
    "print(\"#Train set size:\", len(X_train)) # 실제로 몇 개의 특성이 사용되었는지 확인\n",
    "print(\"#Test set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04d9a727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']\n",
      "['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Twitter\n",
    "okt = Okt()\n",
    "\n",
    "print(okt.morphs(X_train[1])) # 두 번째 리뷰에 대해 형태소 단위로 tokenize\n",
    "print(okt.nouns(X_train[1])) # 두 번째 리뷰에서 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "496c9304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.756\n",
      "#Test set score: 0.694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Twitter 형태소 분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "tfidf = TfidfVectorizer(tokenizer = okt.nouns, max_features = 2000, min_df = 5, max_df = 0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter = 1000) # 충분한 학습을 위해 1000번으로 설정, 기본값은 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print(\"#Train set score: {:.3f}\".format(clf.score(X_train_tfidf, y_train)))\n",
    "print(\"#Test set score: {:.3f}\".format(clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b433ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제영화제목, 예측한 제목, 리뷰\n",
      "('범죄도시', '신과함께', '오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.')\n",
      "('범죄도시', '범죄도시', '조연들이 눈에 박힌다. 간만에 집중 ㅎ')\n",
      "('코코', '코코', '대감동을 선사. 인사이드 아웃을 잇는 픽사의 감동스토리. 신과함께의 멕시코판이라고나할까요??')\n",
      "('신과함께', '신과함께', '돈이 안아까웠던 영화ᆞᆞ  정말 좋았다')\n",
      "('신과함께', '신과함께', '역시 김용화감독이 영화는 잘 만들어요. 이제 VFX 제작 부문도 헐리우드 수준 이상입니다.')\n",
      "('택시운전사', '택시운전사', '민주화를 위해 힘써주신 분들께 감사하는 마음으로 살아야겠다.')\n",
      "('신과함께', '신과함께', '잠만 자다 왔음')\n",
      "('신과함께', '신과함께', '오랜만에 잼있고 좋은 영화를 봤다')\n",
      "('범죄도시', '신과함께', '잼남')\n",
      "('범죄도시', '인피니티 워', '대박~~')\n"
     ]
    }
   ],
   "source": [
    "print('실제영화제목, 예측한 제목, 리뷰')\n",
    "for content in zip(y_test[:10], clf.predict(X_test_tfidf[:10]), X_test[:10]):\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543afa0f",
   "metadata": {},
   "source": [
    "### 성능을 개선하기 위한 노력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59387d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.777\n",
      "#Test set score: 0.695\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=okt.morphs, max_features=2000, min_df=5, max_df=0.5) # 명사 대신 모든 형태소를 사용\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5742994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.784\n",
      "#Test set score: 0.712\n"
     ]
    }
   ],
   "source": [
    "def twit_tokenizer(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=0.5) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "522de611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입/Noun', '하다/Verb', '없다/Adjective', './Punctuation', '어렵다/Adjective', '생각/Noun', '하다/Verb', '필요없다/Adjective', './Punctuation', '내/Noun', '가/Josa', '전투/Noun', '에/Josa', '참여/Noun', '한/Determiner', '듯/Noun', '손/Noun', '에/Josa', '땀/Noun', '이남/Noun', './Punctuation']\n"
     ]
    }
   ],
   "source": [
    "# 모든 형태소를 다 사용하고 품사를 알 수 있도록 하면?\n",
    "def twit_tokenizer2(text):\n",
    "    result = []\n",
    "    for word, tag in okt.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result\n",
    "\n",
    "print(twit_tokenizer2(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9265cc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.789\n",
      "#Test set score: 0.718\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, max_features=2000, min_df=5, max_df=0.5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도\n",
    "print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6611bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Max alpha 1.600 at max validation score 0.727\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
    "    X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "max_score = 0\n",
    "max_alpha = 0\n",
    "for alpha in np.arange(0.1, 10, 0.1): # alpha를 0.1부터 10까지 0.1씩 증가\n",
    "    ridge_clf = RidgeClassifier(alpha=alpha) #릿지 분류기 선언\n",
    "    ridge_clf.fit(X_train_ridge, y_train_ridge) #학습\n",
    "    score = ridge_clf.score(X_val_ridge, y_val_ridge) #검정 데이터셋에 대해 정확도를 측정\n",
    "    if score > max_score: #정확도가 이전의 정확도 최대값보다 크면 최대값을 변경한다.\n",
    "        max_score = score\n",
    "        max_alpha = alpha\n",
    "print('#Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab938ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Ridge Train set score: 0.806\n",
      "#Ridge Test set score: 0.726\n",
      "#Lasso Train set score: 0.703\n",
      "#Lasso Test set score: 0.696\n",
      "#Used features count: 957 out of 2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridge_clf = RidgeClassifier(alpha=1.6)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('#Ridge Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Ridge Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('#Lasso Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Lasso Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba9cb726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.768\n",
      "Test set score: 0.704\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_clf = MultinomialNB(alpha=0.1)\n",
    "NB_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
